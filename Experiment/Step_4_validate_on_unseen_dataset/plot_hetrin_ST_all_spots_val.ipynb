{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "feature_locs = [\n",
    "    \"/cls0.pkl\",\n",
    "    \"/cls1.pkl\",\n",
    "    \"/cls2.pkl\",\n",
    "    \"/cls3.pkl\",\n",
    "    \"/cls4.pkl\",\n",
    "]\n",
    "#/home/shi/WorkSpace/projects/scMultiNet_Data/Step_1_data/Dataset_netrin_ST_all_spot\n",
    "raw_data_loc = root + \"/Step_1_data/Dataset_netrin_ST_all_spot/TrVal_dataset_Ground_Truth.pkl\"\n",
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "\n",
    "save_folder = root + \"/Step_4_data/\"\n",
    "\n",
    "ckpt_folder = root+\"/Step_2_data/Cook/regression/ckpt/model_d0.3_0.629.ckpt\"\n",
    "ckpt_folder_cls = root + \"/Step_2_data/Cook/classification/ckpt/model_0.9019531292560845.ckpt\"\n",
    "train_root = root + \"/Step_1_data/Dataset_netrin_ST_all_spot/train/\"\n",
    "binary_root = root + \"/Step_1_data/Dataset_netrin_ST_all_spot/cls/\"\n",
    "\n",
    "cls_nb = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(code_loc)\n",
    "\n",
    "import dill\n",
    "with open(raw_data_loc, \"rb\") as f:\n",
    "    [trainset,valset,_,label_dict] = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fake_lable_0': 0, 'fake_lable_1': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (4283, 128) (4283, 1)\n",
      "torch.Size([4283, 640]) torch.Size([4283, 1])\n",
      "(4283, 1) (4283, 1) (4283, 1)\n"
     ]
    }
   ],
   "source": [
    "# load model and calc features\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "DIM = 128\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "        if out_key == \"fc1\":\n",
    "            return x\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout2(x)\n",
    "        if out_key == \"fc2\":\n",
    "            return x\n",
    "        x = self.fc3(x)\n",
    "        if out_key == \"all\":\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\"out_key must be one of 'fc1', 'fc2', 'all'\")\n",
    "\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "\n",
    "# 从文件夹中读取所有类的feature matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "read_list = [\"cls0\",\"cls1\",\"cls2\",\"cls3\",\"cls4\"]\n",
    "#-->train\n",
    "train_feat_list = []\n",
    "for i in range(len(read_list)):\n",
    "    with open(train_root+read_list[i]+\".pkl\",\"rb\") as f:\n",
    "        [feat,label] = pickle.load(f)\n",
    "        train_feat_list.append(feat)\n",
    "train_label = label\n",
    "print(len(train_feat_list),train_feat_list[0].shape,train_label.shape)\n",
    "# 合并feat_list中的feature matrix，[sample_nb,feat_dim] -> [sample_nb,feat_dim*5]\n",
    "train_feat = np.concatenate(train_feat_list,axis=1) \n",
    "train_feat = torch.from_numpy(train_feat).float()\n",
    "train_label = torch.from_numpy(train_label).long() \n",
    "# label from [sample_nb,1] -> [sample_nb,class_nb]\n",
    "#train_label = torch.zeros(train_label.shape[0],cls_nb).scatter_(1,train_label,1)\n",
    "print(train_feat.shape,train_label.shape)\n",
    "\n",
    "# get Dataset and DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(train_feat,train_label)\n",
    "\n",
    "trainloader = DataLoader(trainset,batch_size=DIM,shuffle=False)\n",
    "\n",
    "\n",
    "# get model\n",
    "model = FuseNet(in_dim=DIM*5, dropout = 0., h_dim = DIM, out_dim = 1, )\n",
    "\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(ckpt_folder))\n",
    "\n",
    "# get features\n",
    "model.eval()\n",
    "feat_layer = \"fc1\"\n",
    "all_feat = []\n",
    "all_label = []\n",
    "all_pred = []\n",
    "all_prob = []\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs,label = data\n",
    "        feat = model(inputs,out_key=feat_layer)\n",
    "        all_feat.append(feat)\n",
    "        all_label.append(label)\n",
    "        pred = model(inputs,out_key=\"all\")\n",
    "        prob = pred#F.softmax(pred,dim=1)\n",
    "        all_prob.append(prob)\n",
    "\n",
    "embedding = torch.cat(all_feat,dim=0).detach().numpy()\n",
    "labels = torch.cat(all_label,dim=0).detach().numpy()\n",
    "prob = torch.cat(all_prob,dim=0).detach().numpy()\n",
    "print(embedding.shape,labels.shape,prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  4283\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(code_loc)\n",
    "import scLLM\n",
    "\n",
    "# 数据集读取\n",
    "import dill\n",
    "# 用dill打开loc0的pkl 文件读取dataset\n",
    "with open(raw_data_loc,\"rb\") as f:\n",
    "    [dataset_1,dataset_2,_,_] = dill.load(f)\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(dataset_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape,len(dataset_1.sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "\n",
    "data_dict = {\n",
    "    \"sample_id\": dataset_1.sample_id,\n",
    "    \"pred_labels\": prob.squeeze(),\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df.to_csv(save_folder+\"/hetrinST_all_spots_predicted_labels_with_samples.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and calc features\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "DIM = 128\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "        if out_key == \"fc1\":\n",
    "            return x\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout2(x)\n",
    "        if out_key == \"fc2\":\n",
    "            return x\n",
    "        x = self.fc3(x)\n",
    "        if out_key == \"all\":\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\"out_key must be one of 'fc1', 'fc2', 'all'\")\n",
    "\n",
    "# 从文件夹中读取所有类的feature matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "read_list = [\"cls0\",\"cls1\",\"cls2\",\"cls3\",\"cls4\"]\n",
    "#-->train\n",
    "train_feat_list = []\n",
    "for i in range(len(read_list)):\n",
    "    with open(train_root+read_list[i]+\".pkl\",\"rb\") as f:\n",
    "        [feat,label] = pickle.load(f)\n",
    "        train_feat_list.append(feat)\n",
    "train_label = label\n",
    "print(len(train_feat_list),train_feat_list[0].shape,train_label.shape)\n",
    "# 合并feat_list中的feature matrix，[sample_nb,feat_dim] -> [sample_nb,feat_dim*5]\n",
    "train_feat = np.concatenate(train_feat_list,axis=1) \n",
    "train_feat = torch.from_numpy(train_feat).float()\n",
    "train_label = torch.from_numpy(train_label).long() \n",
    "# label from [sample_nb,1] -> [sample_nb,class_nb]\n",
    "#train_label = torch.zeros(train_label.shape[0],cls_nb).scatter_(1,train_label,1)\n",
    "print(train_feat.shape,train_label.shape)\n",
    "\n",
    "# get Dataset and DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(train_feat,train_label)\n",
    "\n",
    "trainloader = DataLoader(trainset,batch_size=DIM,shuffle=False)\n",
    "\n",
    "\n",
    "# get model\n",
    "model = FuseNet(in_dim=DIM*5, dropout = 0., h_dim = DIM, out_dim = 5, )\n",
    "\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(ckpt_folder_cls))\n",
    "\n",
    "# get features\n",
    "model.eval()\n",
    "feat_layer = \"fc1\"\n",
    "all_feat = []\n",
    "all_label = []\n",
    "all_pred = []\n",
    "all_prob = []\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs,label = data\n",
    "        feat = model(inputs,out_key=feat_layer)\n",
    "        all_feat.append(feat)\n",
    "        all_label.append(label)\n",
    "        pred = model(inputs,out_key=\"all\")\n",
    "        prob = pred#F.softmax(pred,dim=1)\n",
    "        all_prob.append(prob)\n",
    "\n",
    "embedding = torch.cat(all_feat,dim=0).detach().numpy()\n",
    "labels = torch.cat(all_label,dim=0).detach().numpy()\n",
    "prob = torch.cat(all_prob,dim=0).detach().numpy()\n",
    "print(embedding.shape,labels.shape,prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "\n",
    "data_dict = {\n",
    "    \"sample_id\": dataset_1.sample_id,\n",
    "    \"pred_labels\": pred.squeeze(),\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df.to_csv(save_folder+\"/hetrinST_all_spots_predicted_cat_with_samples.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label mapping\n",
    "label_dict = {'3d':0, '7d':1, '1d':2, '8h':3, '0d':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用阈值0.5的结果:\n",
      "\n",
      "使用argmax的结果:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "pkl_list = [\"cls0\", \"cls1\", \"cls2\", \"cls3\", \"cls4\"]  # -->train\n",
    "label_dict = {'3d': 0, '7d': 1, '1d': 2, '8h': 3, '0d': 4}\n",
    "\n",
    "# 构建reverse_label_map\n",
    "reverse_label_map = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# 读取sample_id\n",
    "sample_id = dataset_1.sample_id  # 假设dataset_1是包含sample_id的DataFrame或Series\n",
    "\n",
    "# 初始化结果DataFrame\n",
    "thres_columns = [reverse_label_map[i] for i in range(len(label_dict))]\n",
    "result_df_thres = pd.DataFrame(index=sample_id, columns=thres_columns)\n",
    "argmax_columns = [reverse_label_map[i] for i in range(len(label_dict))]\n",
    "result_df_argmax = pd.DataFrame(index=sample_id, columns=argmax_columns)\n",
    "\n",
    "for i in range(len(pkl_list)):\n",
    "    with open(train_root + pkl_list[i] + \".pkl\", \"rb\") as f:\n",
    "        [prob, label] = pickle.load(f)\n",
    "\n",
    "    # softmax后的概率\n",
    "    # 对prob进行softmax操作\n",
    "    prob_softmax = np.exp(prob) / np.sum(np.exp(prob), axis=1, keepdims=True)\n",
    "    # 使用阈值0.5将prob转换为0,1表示\n",
    "    binary_pred_thres = (prob[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    # 使prob\n",
    "    binary_pred_argmax = prob_softmax[:, 1]\n",
    "\n",
    "\n",
    "    # 将结果添加到结果DataFrame中\n",
    "    result_df_thres[reverse_label_map[i]] = binary_pred_thres\n",
    "    result_df_argmax[reverse_label_map[i]] = binary_pred_argmax\n",
    "\n",
    "# 输出结果DataFrame\n",
    "print(\"使用阈值0.5的结果:\")\n",
    "result_df_thres.to_csv(save_folder+\"/hetrinST_all_spots_predicted_thres5cat_with_samples.csv\")\n",
    "print(\"\\n使用argmax的结果:\")\n",
    "result_df_argmax.to_csv(save_folder+\"/hetrinST_all_spots_predicted_prob5cat_with_samples.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

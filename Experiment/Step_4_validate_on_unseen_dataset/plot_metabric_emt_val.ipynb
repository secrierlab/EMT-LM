{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "feature_locs = [\n",
    "    \"/cls0.pkl\",\n",
    "    \"/cls1.pkl\",\n",
    "    \"/cls2.pkl\",\n",
    "    \"/cls3.pkl\",\n",
    "    \"/cls4.pkl\",\n",
    "]\n",
    "\n",
    "raw_data_loc = root + \"/Step_1_data/Dataset_bulk_other/TrVal_dataset_Ground_truth.pkl\"\n",
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "\n",
    "save_folder = root + \"/Step_4_data/\"\n",
    "\n",
    "ckpt_folder = root+\"/Step_2_data/Cook/regression/ckpt/model_d0.3_0.629.ckpt\"\n",
    "ckpt_folder_cls = root + \"/Step_2_data/Cook/classification/ckpt/model_0.9019531292560845.ckpt\"\n",
    "train_root = root + \"/Step_1_data/Dataset_bulk_other/train/\"\n",
    "\n",
    "cls_nb = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(code_loc)\n",
    "\n",
    "import dill\n",
    "with open(raw_data_loc, \"rb\") as f:\n",
    "    [trainset,valset,_,label_dict] = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fake_lable_0': 0, 'fake_lable_1': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (1980, 128) (1980, 1)\n",
      "torch.Size([1980, 640]) torch.Size([1980, 1])\n",
      "(1980, 1) (1980, 1) (1980, 1)\n"
     ]
    }
   ],
   "source": [
    "# load model and calc features\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "DIM = 128\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "        if out_key == \"fc1\":\n",
    "            return x\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout2(x)\n",
    "        if out_key == \"fc2\":\n",
    "            return x\n",
    "        x = self.fc3(x)\n",
    "        if out_key == \"all\":\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\"out_key must be one of 'fc1', 'fc2', 'all'\")\n",
    "\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "\n",
    "# 从文件夹中读取所有类的feature matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "read_list = [\"cls0\",\"cls1\",\"cls2\",\"cls3\",\"cls4\"]\n",
    "#-->train\n",
    "train_feat_list = []\n",
    "for i in range(len(read_list)):\n",
    "    with open(train_root+read_list[i]+\".pkl\",\"rb\") as f:\n",
    "        [feat,label] = pickle.load(f)\n",
    "        train_feat_list.append(feat)\n",
    "train_label = label\n",
    "print(len(train_feat_list),train_feat_list[0].shape,train_label.shape)\n",
    "# 合并feat_list中的feature matrix，[sample_nb,feat_dim] -> [sample_nb,feat_dim*5]\n",
    "train_feat = np.concatenate(train_feat_list,axis=1) \n",
    "train_feat = torch.from_numpy(train_feat).float()\n",
    "train_label = torch.from_numpy(train_label).long() \n",
    "# label from [sample_nb,1] -> [sample_nb,class_nb]\n",
    "#train_label = torch.zeros(train_label.shape[0],cls_nb).scatter_(1,train_label,1)\n",
    "print(train_feat.shape,train_label.shape)\n",
    "\n",
    "# get Dataset and DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(train_feat,train_label)\n",
    "\n",
    "trainloader = DataLoader(trainset,batch_size=DIM,shuffle=False)\n",
    "\n",
    "\n",
    "# get model\n",
    "model = FuseNet(in_dim=DIM*5, dropout = 0., h_dim = DIM, out_dim = 1, )\n",
    "\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(ckpt_folder))\n",
    "\n",
    "# get features\n",
    "model.eval()\n",
    "feat_layer = \"fc1\"\n",
    "all_feat = []\n",
    "all_label = []\n",
    "all_pred = []\n",
    "all_prob = []\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs,label = data\n",
    "        feat = model(inputs,out_key=feat_layer)\n",
    "        all_feat.append(feat)\n",
    "        all_label.append(label)\n",
    "        pred = model(inputs,out_key=\"all\")\n",
    "        prob = pred#F.softmax(pred,dim=1)\n",
    "        all_prob.append(prob)\n",
    "\n",
    "embedding = torch.cat(all_feat,dim=0).detach().numpy()\n",
    "labels = torch.cat(all_label,dim=0).detach().numpy()\n",
    "prob = torch.cat(all_prob,dim=0).detach().numpy()\n",
    "print(embedding.shape,labels.shape,prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  1980\n",
      "{'fake_lable_0': 0, 'fake_lable_1': 1}\n",
      "{0: 'fake_lable_0', 1: 'fake_lable_1'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(code_loc)\n",
    "import scLLM\n",
    "\n",
    "# 数据集读取\n",
    "import dill\n",
    "# 用dill打开loc0的pkl 文件读取dataset\n",
    "with open(raw_data_loc,\"rb\") as f:\n",
    "    [dataset_1,dataset_2,_,_] = dill.load(f)\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(dataset_1))\n",
    "\n",
    "print(label_dict)\n",
    "# reverse label_dict\n",
    "rev_label_dict = {v:k for k,v in label_dict.items()}\n",
    "print(rev_label_dict)\n",
    "vocab = \"/home/shi/WorkSpace/projects/scLLM_workspace/vocab_16k.json\"\n",
    "# read vocab\n",
    "import json\n",
    "with open(vocab,\"r\") as f:\n",
    "    gene_names = json.load(f)\n",
    "# 获取vocab按照value排序的key 的 list\n",
    "#gene_names = [k for k,v in sorted(vocab.items(),key=lambda x:x[1])]\n",
    "    \n",
    "import scanpy as sc\n",
    "# 第 1 步: 读取数据\n",
    "exp_raw_data = dataset_1.data\n",
    "\n",
    "root_label_value = label_dict[\"fake_lable_0\"]\n",
    "# 第 2 步：数据准备\n",
    "adata = sc.AnnData(X=exp_raw_data)\n",
    "adata.var_names = [name for name, _ in sorted(gene_names.items(), key=lambda x: x[1])]\n",
    "adata.obs['labels'] = labels\n",
    "adata.obsm['X_emb'] = embedding  # embedding 是嵌入矩阵\n",
    "\n",
    "adata.obs[\"sample_id\"] = dataset_1.sample_id\n",
    "\n",
    "\n",
    "l_list = adata.obs['labels'].to_list()\n",
    "l_list = [rev_label_dict[i] for i in l_list]\n",
    "adata.obs['GT'] = l_list\n",
    "\n",
    "# preds to str with label_dict\n",
    "#pred_name = [rev_label_dict[i] for i in preds]\n",
    "adata.obs[\"pred_labels\"] = prob*10 #preds *10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "\n",
    "data_dict = {\n",
    "    \"sample_id\": adata.obs[\"sample_id\"].to_list(),\n",
    "    \"pred_labels\": adata.obs[\"pred_labels\"].to_list(),\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df.to_csv(save_folder+\"/metabric_predicted_labels_with_samples.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (1980, 128) (1980, 1)\n",
      "torch.Size([1980, 640]) torch.Size([1980, 1])\n",
      "(1980, 512) (1980, 1) (1980, 5)\n"
     ]
    }
   ],
   "source": [
    "# load model and calc features\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "DIM = 128\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FuseNet(nn.Module):\n",
    "    def __init__(self,in_dim=128*5, dropout = 0., h_dim = 128, out_dim = 1, ):\n",
    "        nn.Module.__init__(self,)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=512, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x, out_key:str = \"all\"):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dropout1(x)\n",
    "        if out_key == \"fc1\":\n",
    "            return x\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout2(x)\n",
    "        if out_key == \"fc2\":\n",
    "            return x\n",
    "        x = self.fc3(x)\n",
    "        if out_key == \"all\":\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(\"out_key must be one of 'fc1', 'fc2', 'all'\")\n",
    "\n",
    "# 从文件夹中读取所有类的feature matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "read_list = [\"cls0\",\"cls1\",\"cls2\",\"cls3\",\"cls4\"]\n",
    "#-->train\n",
    "train_feat_list = []\n",
    "for i in range(len(read_list)):\n",
    "    with open(train_root+read_list[i]+\".pkl\",\"rb\") as f:\n",
    "        [feat,label] = pickle.load(f)\n",
    "        train_feat_list.append(feat)\n",
    "train_label = label\n",
    "print(len(train_feat_list),train_feat_list[0].shape,train_label.shape)\n",
    "# 合并feat_list中的feature matrix，[sample_nb,feat_dim] -> [sample_nb,feat_dim*5]\n",
    "train_feat = np.concatenate(train_feat_list,axis=1) \n",
    "train_feat = torch.from_numpy(train_feat).float()\n",
    "train_label = torch.from_numpy(train_label).long() \n",
    "# label from [sample_nb,1] -> [sample_nb,class_nb]\n",
    "#train_label = torch.zeros(train_label.shape[0],cls_nb).scatter_(1,train_label,1)\n",
    "print(train_feat.shape,train_label.shape)\n",
    "\n",
    "# get Dataset and DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(train_feat,train_label)\n",
    "\n",
    "trainloader = DataLoader(trainset,batch_size=DIM,shuffle=False)\n",
    "\n",
    "\n",
    "# get model\n",
    "model = FuseNet(in_dim=DIM*5, dropout = 0., h_dim = DIM, out_dim = 5, )\n",
    "\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load(ckpt_folder_cls))\n",
    "\n",
    "# get features\n",
    "model.eval()\n",
    "feat_layer = \"fc1\"\n",
    "all_feat = []\n",
    "all_label = []\n",
    "all_pred = []\n",
    "all_prob = []\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        inputs,label = data\n",
    "        feat = model(inputs,out_key=feat_layer)\n",
    "        all_feat.append(feat)\n",
    "        all_label.append(label)\n",
    "        pred = model(inputs,out_key=\"all\")\n",
    "        prob = pred#F.softmax(pred,dim=1)\n",
    "        all_prob.append(prob)\n",
    "\n",
    "embedding = torch.cat(all_feat,dim=0).detach().numpy()\n",
    "labels = torch.cat(all_label,dim=0).detach().numpy()\n",
    "prob = torch.cat(all_prob,dim=0).detach().numpy()\n",
    "print(embedding.shape,labels.shape,prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(prob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "\n",
    "data_dict = {\n",
    "    \"sample_id\": adata.obs[\"sample_id\"].to_list(),\n",
    "    \"pred_labels\": pred.squeeze(),\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df.to_csv(save_folder+\"/metabric_predicted_cat_with_samples.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

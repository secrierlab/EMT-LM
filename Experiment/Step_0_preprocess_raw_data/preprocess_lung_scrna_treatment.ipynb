{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "save_root = root + \"/Step_1_data/Dataset_scLung/\" \n",
    "import sys\n",
    "sys.path.append(code_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a vocab list\n",
    "# this related with the gene2vec model\n",
    "#----> pre-trained part \n",
    "vocab_loc = code_loc +\"/support_data/vocab_gene2vec_16906.pkl\"\n",
    "target_label = 'Ground_Truth' # the label to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = root+\"/Step_0_data/lung_cancer_scrna_treatment.csv\"\n",
    "data_path = root +  \"/Step_0_data/2024_03_13_EMT_sc_lung_cancer_scrna_treatment.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A10_1001000407</th>\n",
       "      <th>A10_1001000408</th>\n",
       "      <th>A10_1001000412</th>\n",
       "      <th>A10_B003518</th>\n",
       "      <th>A10_B003523</th>\n",
       "      <th>A10_B003527</th>\n",
       "      <th>A10_B003529</th>\n",
       "      <th>A10_B003588</th>\n",
       "      <th>A11_1001000407</th>\n",
       "      <th>...</th>\n",
       "      <th>O15_B003183</th>\n",
       "      <th>O1_B001546</th>\n",
       "      <th>O20_B003179</th>\n",
       "      <th>O8_B001544</th>\n",
       "      <th>P10_B001546</th>\n",
       "      <th>P12_B003179</th>\n",
       "      <th>P14_B003179</th>\n",
       "      <th>P17_B003183</th>\n",
       "      <th>P21_B003179</th>\n",
       "      <th>P8_B001546</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1BG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2M-AS1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>LOC101928989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11925</th>\n",
       "      <td>LOC101928992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>LOC101928994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>LOC101928995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>LOC101929019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11929 rows × 3755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  A10_1001000407  A10_1001000408  A10_1001000412  \\\n",
       "0              A1BG               0               0               0   \n",
       "1          A1BG-AS1               0               0               0   \n",
       "2              A1CF               0               0               0   \n",
       "3               A2M               0               0               0   \n",
       "4           A2M-AS1               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "11924  LOC101928989               0               0               0   \n",
       "11925  LOC101928992               0               0               0   \n",
       "11926  LOC101928994               0               0               0   \n",
       "11927  LOC101928995               0               0               0   \n",
       "11928  LOC101929019               0               0               0   \n",
       "\n",
       "       A10_B003518  A10_B003523  A10_B003527  A10_B003529  A10_B003588  \\\n",
       "0                0            0            0            7            0   \n",
       "1                0            0            0            0            0   \n",
       "2                0            0            0            0            0   \n",
       "3                0            0            0            0            0   \n",
       "4                0            0            0            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "11924            0            0            0            0            0   \n",
       "11925            0            0            0            0            0   \n",
       "11926            0            0            0            0          135   \n",
       "11927            0            0            0            0            0   \n",
       "11928            0            0            0            0            0   \n",
       "\n",
       "       A11_1001000407  ...  O15_B003183  O1_B001546  O20_B003179  O8_B001544  \\\n",
       "0                   0  ...          0.0         0.0          0.0         0.0   \n",
       "1                   0  ...          0.0         0.0          0.0         0.0   \n",
       "2                   0  ...          0.0         0.0          0.0         0.0   \n",
       "3                   0  ...          0.0         0.0          0.0         3.0   \n",
       "4                   0  ...          0.0         0.0          0.0         0.0   \n",
       "...               ...  ...          ...         ...          ...         ...   \n",
       "11924               0  ...          0.0         0.0          0.0         0.0   \n",
       "11925               0  ...          0.0         0.0          0.0         0.0   \n",
       "11926               0  ...         39.0         0.0         28.0         0.0   \n",
       "11927               0  ...          0.0         0.0          0.0         0.0   \n",
       "11928               0  ...          NaN         NaN          NaN         NaN   \n",
       "\n",
       "       P10_B001546  P12_B003179  P14_B003179  P17_B003183  P21_B003179  \\\n",
       "0              0.0          0.0          0.0          0.0          0.0   \n",
       "1              0.0          0.0          0.0          0.0          0.0   \n",
       "2              0.0          0.0          0.0          0.0          1.0   \n",
       "3              0.0          0.0          0.0         14.0          0.0   \n",
       "4              0.0          0.0          0.0          0.0          0.0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "11924          0.0          0.0          0.0          0.0          0.0   \n",
       "11925          0.0          0.0          0.0          0.0          0.0   \n",
       "11926          0.0          0.0         15.0          0.0          0.0   \n",
       "11927          0.0          0.0          0.0          0.0          0.0   \n",
       "11928          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       P8_B001546  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "11924         0.0  \n",
       "11925         0.0  \n",
       "11926         0.0  \n",
       "11927         0.0  \n",
       "11928         NaN  \n",
       "\n",
       "[11929 rows x 3755 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "AnnData object with n_obs × n_vars = 3754 × 11928\n",
      "    obs: 'Ground_Truth'                 Ground_Truth\n",
      "A10_1001000407             0\n",
      "A10_1001000408             1\n",
      "A10_1001000412             0\n",
      "A10_B003518                1\n",
      "A10_B003523                1\n",
      "...                      ...\n",
      "P12_B003179                1\n",
      "P14_B003179                1\n",
      "P17_B003183                0\n",
      "P21_B003179                1\n",
      "P8_B001546                 1\n",
      "\n",
      "[3754 rows x 1 columns] Empty DataFrame\n",
      "Columns: []\n",
      "Index: [A1BG, A1BG-AS1, A1CF, A2M, A2M-AS1, A2ML1, A2MP1, A3GALT2, A4GALT, A4GNT, AA06, AAAS, AACS, AACSP1, AADAC, AADACL2, AADACL2-AS1, AADACL3, AADACL4, AADACP1, AADAT, AAED1, AAGAB, AAK1, AAMDC, AAMP, AANAT, AAR2, AARD, AARS, AARS2, AARSD1, AASDH, AASDHPPT, AASS, AATBC, AATF, AATK, AATK-AS1, ABALON, ABAT, ABCA1, ABCA10, ABCA11P, ABCA12, ABCA13, ABCA17P, ABCA2, ABCA3, ABCA4, ABCA5, ABCA6, ABCA7, ABCA8, ABCA9, ABCA9-AS1, ABCB1, ABCB10, ABCB11, ABCB4, ABCB5, ABCB6, ABCB7, ABCB8, ABCB9, ABCC1, ABCC10, ABCC11, ABCC12, ABCC13, ABCC2, ABCC3, ABCC4, ABCC5, ABCC5-AS1, ABCC6, ABCC6P1, ABCC6P2, ABCC8, ABCC9, ABCD1, ABCD2, ABCD3, ABCD4, ABCE1, ABCF1, ABCF2, ABCF3, ABCG1, ABCG2, ABCG4, ABCG5, ABCG8, ABHD1, ABHD10, ABHD11, ABHD11-AS1, ABHD12, ABHD12B, ABHD13, ...]\n",
      "\n",
      "[11928 rows x 0 columns] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "mask = df.isna().any(axis = 1)\n",
    "df = df[~mask]\n",
    "\n",
    "gene_id = df.iloc[:,0].values\n",
    "sample_id = df.columns[1:].values\n",
    "data_x = df.iloc[:,1:].values\n",
    "\n",
    "import numpy as np\n",
    "# confirm nan and inf in data_x\n",
    "print(np.isnan(data_x).any(), np.isinf(data_x).any())\n",
    "# set nan to 0\n",
    "data_x = np.nan_to_num(data_x)\n",
    "# set inf to 0\n",
    "data_x = np.where(data_x == np.inf, 0, data_x)\n",
    "\n",
    "# normalize the data to 0-100\n",
    "# 找到数据的最小值和最大值\n",
    "#min_val = np.min(data_x)\n",
    "#max_val = np.max(data_x)\n",
    "#print(min_val, max_val )\n",
    "# 将数据归一化到 0 到 100 的范围\n",
    "#normalized_data_x = 100 * (data_x - min_val) / (max_val - min_val)\n",
    "#print(normalized_data_x.shape)\n",
    "# create the adata matrix\n",
    "import anndata\n",
    "adata = anndata.AnnData(X = data_x.T, obs = pd.DataFrame(index = sample_id), var = pd.DataFrame(index = gene_id))\n",
    "adata.obs[\"Ground_Truth\"] = np.random.choice([0,1], adata.shape[0])\n",
    "print(adata, adata.obs, adata.var, adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground_Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A10_1001000407</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_1001000408</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_1001000412</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_B003518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10_B003523</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P12_B003179</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P14_B003179</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_B003183</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P21_B003179</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P8_B001546</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3754 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ground_Truth\n",
       "A10_1001000407             0\n",
       "A10_1001000408             1\n",
       "A10_1001000412             0\n",
       "A10_B003518                1\n",
       "A10_B003523                1\n",
       "...                      ...\n",
       "P12_B003179                1\n",
       "P14_B003179                1\n",
       "P17_B003183                0\n",
       "P21_B003179                1\n",
       "P8_B001546                 1\n",
       "\n",
       "[3754 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.write(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 3754 × 11929\n",
      "    obs: 'Ground_Truth'\n",
      "Index(['A10_1001000407', 'A10_1001000408', 'A10_1001000412', 'A10_B003518',\n",
      "       'A10_B003523', 'A10_B003527', 'A10_B003529', 'A10_B003588',\n",
      "       'A11_1001000407', 'A11_1001000408',\n",
      "       ...\n",
      "       'O15_B003183', 'O1_B001546', 'O20_B003179', 'O8_B001544', 'P10_B001546',\n",
      "       'P12_B003179', 'P14_B003179', 'P17_B003183', 'P21_B003179',\n",
      "       'P8_B001546'],\n",
      "      dtype='object', length=3754)\n",
      "Index(['A1BG', 'A1BG-AS1', 'A1CF', 'A2M', 'A2M-AS1', 'A2ML1', 'A2MP1',\n",
      "       'A3GALT2', 'A4GALT', 'A4GNT',\n",
      "       ...\n",
      "       'LOC101928973', 'LOC101928977', 'LOC101928978', 'LOC101928979',\n",
      "       'LOC101928988', 'LOC101928989', 'LOC101928992', 'LOC101928994',\n",
      "       'LOC101928995', 'LOC101929019'],\n",
      "      dtype='object', length=11929)\n",
      " negative values: 0\n"
     ]
    }
   ],
   "source": [
    "# check the data\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "adata = sc.read(data_path)\n",
    "\n",
    "print(adata)\n",
    "print(adata.obs.index)\n",
    "print(adata.var.index)\n",
    "print(f\" negative values: {np.sum(adata.X<0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# adata.X 有多少nan\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# 假设 adata.X 是你的稀疏矩阵\n",
    "# 首先，检查它是否为稀疏矩阵\n",
    "if issparse(adata.X):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_para(var_idx=None, obs_idx='Ground_Truth', vocab_loc='/home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json', gene_vocab=None, use_key='X', filter_gene_by_counts=False, filter_cell_by_counts=0, normalize_total=10000.0, result_normed_key='X_normed', log1p=True, result_log1p_key='X_log1p', log1p_base=2, subset_hvg=False, hvg_use_key=None, hvg_flavor='seurat_v3', binning=None, result_binned_key='X_binned', tokenize_name='scBERT', return_pt=True, append_cls=True, include_zero_gene=False, cls_token='<cls>', max_len=16000, pad_token='<pad>', pad_value=-2, cls_appended=True, mask_ratio=0.15, mask_value=-1, preprocessed_loc=None, data_layer_name='X_log1p', label_key='Ground_Truth', batch_label_key=None, cls_nb=5, binarize=None, bins=None, bin_min=None, bin_max=None, save_in_obs=True, auto_map_str_labels=True, map_dict=None, n_splits=1, test_size=None, random_state=2023, shuffle=True, sort_seq_batch=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT\n",
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT \n",
    "dataset_para_cls = Dataset_para(\n",
    "                            var_idx=None,\n",
    "                            obs_idx=\"Ground_Truth\",\n",
    "                            vocab_loc=code_loc + \"/Experiment/support_data/vocab_16k.json\",\n",
    "                            filter_gene_by_counts=False,\n",
    "                            filter_cell_by_counts=0,\n",
    "                            log1p=True,\n",
    "                            log1p_base=2,\n",
    "\n",
    "                            #\n",
    "                            tokenize_name=\"scBERT\",\n",
    "                            cls_nb=5,\n",
    "                            data_layer_name=\"X_log1p\",\n",
    "                            label_key = target_label,#\"Ground_truth\",#\"Ground_truth\",\n",
    "\n",
    "                            test_size=None,#0.2, #use all data to inference\n",
    "                            binarize=None, # not binarize use original label\n",
    "\n",
    "                            )\n",
    "\n",
    "dataset_para_reg = Dataset_para(\n",
    "        vocab_loc=code_loc +\"/Experiment/support_data/vocab_16k.json\",\n",
    "        var_idx = None,#\"genes.gene_short_name\",\n",
    "        obs_idx=\"pseudotimes\",\n",
    "        filter_gene_by_counts=False,\n",
    "        filter_cell_by_counts=200,\n",
    "        log1p=True,\n",
    "        log1p_base=2,\n",
    "\n",
    "        tokenize_name=\"scBERT\",\n",
    "        cls_nb=1,\n",
    "        data_layer_name=\"X_log1p\",\n",
    "\n",
    "        auto_map_str_labels=False,\n",
    "        label_key = target_label,#\"pseudotimes\",\n",
    "\n",
    "        test_size=None,#0.2, #use all data to inference\n",
    "        binarize=None, # not binarize use original label for regression\n",
    "    )\n",
    "\n",
    "dataset_para = dataset_para_cls#dataset_para_cls\n",
    "print(dataset_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Initializing preprocessor ...\n",
      "scLLM - INFO - use default vocab from dataset_para\n",
      "scLLM - INFO - load vocab from /home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json\n",
      "scLLM - INFO - Load data from anndata object.\n",
      "scLLM - DEBUG - In original adata with gene 11929\n",
      "scLLM - DEBUG - In original adata with gene 11929\n",
      "scLLM - DEBUG - processing 0/16906\n",
      "scLLM - DEBUG - processing 2000/16906\n",
      "scLLM - DEBUG - processing 4000/16906\n",
      "scLLM - DEBUG - processing 6000/16906\n",
      "scLLM - DEBUG - processing 8000/16906\n",
      "scLLM - DEBUG - processing 10000/16906\n",
      "scLLM - DEBUG - processing 12000/16906\n",
      "scLLM - DEBUG - processing 14000/16906\n",
      "scLLM - DEBUG - processing 16000/16906\n",
      "scLLM - INFO - create anndata in scLLM format..\n",
      "scLLM - DEBUG - restore anndata in scLLM format..\n",
      "scLLM - INFO - Done.\n",
      "scLLM - INFO - Preprocessing data with shape: (3754, 16906) ...\n",
      "scLLM - INFO - Filtering cells by counts ...\n",
      "scLLM - INFO - Filtered cells: 3754\n",
      "scLLM - INFO - Normalizing total counts ...\n",
      "scLLM - INFO - Log1p transforming ...\n",
      "scLLM - INFO - Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# if this is the first time to run, need this block to init translate=True\n",
    "# init preprocessor\n",
    "from scLLM.Dataset.Reader import scReader\n",
    "data_reader = scReader(dataset_para=dataset_para)\n",
    "# init vocab\n",
    "data_reader.init_vocab()\n",
    "\n",
    "# load data\n",
    "data_reader.load_adata(loc = data_path,translate=True)\n",
    "\n",
    "## preprocess\n",
    "data_reader.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16906"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reader.adata.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择前的数据矩阵形状 (3754, 16906)\n",
      "选择后的数据矩阵形状 (3754, 16906)\n"
     ]
    }
   ],
   "source": [
    "target_stimulate = \"TGFb\"\n",
    "target_cellline = None #\"A549\" 'DU145', 'MCF7', 'OVCA420'\n",
    "map_stimulus = False\n",
    "map_cancer_type = False\n",
    "\n",
    "print(f\"选择前的数据矩阵形状 {data_reader.adata.shape}\")\n",
    "if map_stimulus:\n",
    "    stimilus_map = data_reader.adata.obs['stimulus']==target_stimulate\n",
    "    # filter out cells that are not stimulated by TGFb\n",
    "    new_adata = data_reader.adata[stimilus_map,:]\n",
    "    data_reader.adata = new_adata\n",
    "\n",
    "if map_cancer_type:\n",
    "    cancer_type_map = data_reader.adata.obs['CellLine']==target_cellline\n",
    "    # filter out cells that are not stimulated by TGFb\n",
    "    new_adata = data_reader.adata[cancer_type_map,:]\n",
    "    data_reader.adata = new_adata\n",
    "\n",
    "print(f\"选择后的数据矩阵形状 {data_reader.adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# get layer X_log1p\n",
    "data = data_reader.adata.layers[\"X_log1p\"] \n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "# set nan to 0\n",
    "if isinstance(data, csr_matrix):\n",
    "    # 使用 CSR 格式的稀疏矩阵可以直接通过 data.data 访问非零元素\n",
    "    data.data[np.isnan(data.data)] = 0\n",
    "    # 注意: 这里没有改变矩阵的稀疏结构，只是将非零元素中的 NaN 值替换为 0\n",
    "    data.data[np.isinf(data.data)] = data.data.max()\n",
    "else:\n",
    "    # 如果 data 不是稀疏矩阵，可以直接使用 numpy 的方法\n",
    "    data[np.isnan(data)] = 0\n",
    "    data[np.isinf(data)] = data.max()\n",
    "\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count}\")\n",
    "data_reader.adata.layers[\"X_log1p\"]  = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# data <0 的个数\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.sum(data.toarray()<0)\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.sum(data<0)\n",
    "\n",
    "print(f\"Negative values in adata.X: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "label_unique = data_reader.adata.obs[dataset_para.label_key].unique()\n",
    "print(label_unique)\n",
    "label_dict = {'fake_lable_0':0,'fake_lable_1':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fake label\n",
    "#data_reader.adata.obs[dataset_para.label_key]\n",
    "revert_dict = {v:k for k,v in label_dict.items()}\n",
    "# map to str label\n",
    "data_reader.adata.obs[dataset_para.label_key] = data_reader.adata.obs[dataset_para.label_key].map(revert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Map string labels to int automatically.\n",
      "scLLM - INFO - Mapping from {'fake_lable_1': 0, 'fake_lable_0': 1}\n",
      "scLLM - INFO - Discritize label Ground_Truth in obs_names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  3754\n",
      "no valset\n",
      "{'fake_lable_0': 0, 'fake_lable_1': 1}\n",
      "weights:  None\n"
     ]
    }
   ],
   "source": [
    "trainset,valset,weights = data_reader.postprocess()\n",
    "\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(trainset))\n",
    "print(\"valset size: \",len(valset)) if valset is not None else print(\"no valset\")\n",
    "print(label_dict)\n",
    "print(\"weights: \",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.sample_id = data_reader.adata.obs.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754 3754\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset.sample_id), len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# 为trainset 添加其他labels\n",
    "\n",
    "#target_task = f\"/TrVal_dataset_GT_{target_stimulate}_{target_cellline}.pkl\"\n",
    "target_task = f\"/TrVal_dataset_{target_label}.pkl\"\n",
    "loc = save_root + target_task\n",
    "# 保存 trainset 到文件，并关联相应labels\n",
    "with open(loc,\"wb\") as f:\n",
    "    dill.dump([trainset,valset,weights,label_dict],f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

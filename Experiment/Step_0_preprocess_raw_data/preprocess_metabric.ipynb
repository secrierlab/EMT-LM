{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "save_root = root + \"/Step_1_data/Dataset_bulk_other/\"\n",
    "import sys\n",
    "sys.path.append(code_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a vocab list\n",
    "# this related with the gene2vec model\n",
    "#----> pre-trained part\n",
    "vocab_loc = code_loc +\"/support_data/vocab_gene2vec_16906.pkl\"\n",
    "target_label = 'Ground_Truth' # the label to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = root+\"/Step_0_data/gene_expression_metabric.csv\"\n",
    "csv_path2 = root + \"/Step_0_data/2024_3_27_gene_expression_metabric.csv\"\n",
    "data_path = root +  \"/Step_0_data/2024_02_25_EMT_bulk_metabric.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(csv_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MB.0362</th>\n",
       "      <th>MB.0346</th>\n",
       "      <th>MB.0386</th>\n",
       "      <th>MB.0574</th>\n",
       "      <th>MB.0185</th>\n",
       "      <th>MB.0503</th>\n",
       "      <th>MB.0641</th>\n",
       "      <th>MB.0201</th>\n",
       "      <th>MB.0218</th>\n",
       "      <th>...</th>\n",
       "      <th>MB.6192</th>\n",
       "      <th>MB.4820</th>\n",
       "      <th>MB.5527</th>\n",
       "      <th>MB.5167</th>\n",
       "      <th>MB.5465</th>\n",
       "      <th>MB.5453</th>\n",
       "      <th>MB.5471</th>\n",
       "      <th>MB.5127</th>\n",
       "      <th>MB.4313</th>\n",
       "      <th>MB.4823</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RERE</td>\n",
       "      <td>-0.7139</td>\n",
       "      <td>1.2266</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>-0.4399</td>\n",
       "      <td>-0.5958</td>\n",
       "      <td>0.4729</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>-1.1900</td>\n",
       "      <td>-0.9265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4596</td>\n",
       "      <td>1.8975</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>1.1942</td>\n",
       "      <td>-1.7974</td>\n",
       "      <td>1.1339</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>-0.3529</td>\n",
       "      <td>-1.2327</td>\n",
       "      <td>1.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNF165</td>\n",
       "      <td>-0.4606</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>-0.6800</td>\n",
       "      <td>-1.0563</td>\n",
       "      <td>-0.0377</td>\n",
       "      <td>-0.6829</td>\n",
       "      <td>-0.2854</td>\n",
       "      <td>-0.4336</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0927</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>-0.2898</td>\n",
       "      <td>3.5763</td>\n",
       "      <td>1.3429</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>1.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHF7</td>\n",
       "      <td>-0.3325</td>\n",
       "      <td>-1.0617</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>-0.2982</td>\n",
       "      <td>-1.2422</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>-0.5011</td>\n",
       "      <td>-0.6418</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>-0.9275</td>\n",
       "      <td>-0.0587</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>-0.0311</td>\n",
       "      <td>4.4925</td>\n",
       "      <td>-0.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIDEA</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>-1.0394</td>\n",
       "      <td>3.2991</td>\n",
       "      <td>-0.2632</td>\n",
       "      <td>-1.0949</td>\n",
       "      <td>1.2628</td>\n",
       "      <td>2.0796</td>\n",
       "      <td>-0.8310</td>\n",
       "      <td>-0.6602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>-0.7126</td>\n",
       "      <td>-0.1523</td>\n",
       "      <td>-0.7593</td>\n",
       "      <td>-0.7141</td>\n",
       "      <td>-0.4324</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>-0.4003</td>\n",
       "      <td>2.4698</td>\n",
       "      <td>-0.7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TENT2</td>\n",
       "      <td>-0.7853</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>-0.6649</td>\n",
       "      <td>2.1640</td>\n",
       "      <td>-0.2031</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>0.6046</td>\n",
       "      <td>-1.7557</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>-0.1102</td>\n",
       "      <td>1.2719</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>-1.0301</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>2.4222</td>\n",
       "      <td>-3.2853</td>\n",
       "      <td>0.4181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20382</th>\n",
       "      <td>VPS72</td>\n",
       "      <td>-0.2908</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>-0.1057</td>\n",
       "      <td>-0.1657</td>\n",
       "      <td>-0.4730</td>\n",
       "      <td>1.4719</td>\n",
       "      <td>-0.5683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9195</td>\n",
       "      <td>-1.4857</td>\n",
       "      <td>-1.4543</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>-0.3989</td>\n",
       "      <td>-1.5529</td>\n",
       "      <td>-0.6349</td>\n",
       "      <td>-0.8160</td>\n",
       "      <td>-1.0902</td>\n",
       "      <td>-0.2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20383</th>\n",
       "      <td>CSMD3</td>\n",
       "      <td>-0.5286</td>\n",
       "      <td>-0.4379</td>\n",
       "      <td>6.9258</td>\n",
       "      <td>1.0466</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>-0.1987</td>\n",
       "      <td>-0.6742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3776</td>\n",
       "      <td>-0.6366</td>\n",
       "      <td>-0.0607</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>-0.3231</td>\n",
       "      <td>-0.1251</td>\n",
       "      <td>-0.4265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20384</th>\n",
       "      <td>CC2D1A</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>-0.7520</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>-0.3376</td>\n",
       "      <td>-0.4705</td>\n",
       "      <td>-0.6036</td>\n",
       "      <td>-1.1946</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5877</td>\n",
       "      <td>-1.1169</td>\n",
       "      <td>-0.5420</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>2.5337</td>\n",
       "      <td>-0.8272</td>\n",
       "      <td>-0.1200</td>\n",
       "      <td>4.2708</td>\n",
       "      <td>-1.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20385</th>\n",
       "      <td>IGSF9</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>1.2968</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>-0.1634</td>\n",
       "      <td>-0.2418</td>\n",
       "      <td>-0.2545</td>\n",
       "      <td>-0.9814</td>\n",
       "      <td>1.9240</td>\n",
       "      <td>-0.6869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6217</td>\n",
       "      <td>-1.5481</td>\n",
       "      <td>-1.2088</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.3821</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>-0.5648</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>0.9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20386</th>\n",
       "      <td>FAM71A</td>\n",
       "      <td>-1.1278</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>-0.3571</td>\n",
       "      <td>-1.0923</td>\n",
       "      <td>-1.2238</td>\n",
       "      <td>-0.9668</td>\n",
       "      <td>-1.3778</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4746</td>\n",
       "      <td>1.4956</td>\n",
       "      <td>2.2203</td>\n",
       "      <td>0.3532</td>\n",
       "      <td>-0.2418</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>-0.9335</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.4096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20387 rows × 1981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  MB.0362  MB.0346  MB.0386  MB.0574  MB.0185  MB.0503  \\\n",
       "0           RERE  -0.7139   1.2266  -0.0053  -0.4399  -0.5958   0.4729   \n",
       "1         RNF165  -0.4606   0.3564  -0.6800  -1.0563  -0.0377  -0.6829   \n",
       "2           PHF7  -0.3325  -1.0617   0.2587  -0.2982  -1.2422   0.0558   \n",
       "3          CIDEA  -0.0129  -1.0394   3.2991  -0.2632  -1.0949   1.2628   \n",
       "4          TENT2  -0.7853   0.0337  -0.6649   2.1640  -0.2031   1.0304   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "20382      VPS72  -0.2908   0.3443   0.4818   0.2503  -0.1057  -0.1657   \n",
       "20383      CSMD3  -0.5286  -0.4379   6.9258   1.0466  -0.1060   0.3284   \n",
       "20384     CC2D1A   0.0068  -0.7520   0.0519   0.2502  -0.3376  -0.4705   \n",
       "20385      IGSF9   0.4053   1.2968   0.7962  -0.1634  -0.2418  -0.2545   \n",
       "20386     FAM71A  -1.1278   0.0321   0.6608  -0.3571  -1.0923  -1.2238   \n",
       "\n",
       "       MB.0641  MB.0201  MB.0218  ...  MB.6192  MB.4820  MB.5527  MB.5167  \\\n",
       "0       0.4974  -1.1900  -0.9265  ...  -0.4596   1.8975   1.1120   1.1942   \n",
       "1      -0.2854  -0.4336  -0.0496  ...  -1.0927   0.9103  -0.0023  -0.2898   \n",
       "2      -0.5011  -0.6418  -0.0694  ...  -0.0725   0.7219   0.1402   0.8718   \n",
       "3       2.0796  -0.8310  -0.6602  ...   0.0679  -0.7126  -0.1523  -0.7593   \n",
       "4       0.6046  -1.7557   0.3588  ...   0.6400  -0.1102   1.2719   0.8178   \n",
       "...        ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "20382  -0.4730   1.4719  -0.5683  ...  -0.9195  -1.4857  -1.4543   0.3791   \n",
       "20383   0.0993  -0.1987  -0.6742  ...  -0.3776  -0.6366  -0.0607  -0.0475   \n",
       "20384  -0.6036  -1.1946   0.5151  ...  -0.5877  -1.1169  -0.5420   0.2947   \n",
       "20385  -0.9814   1.9240  -0.6869  ...  -0.6217  -1.5481  -1.2088   0.4594   \n",
       "20386  -0.9668  -1.3778   0.8013  ...  -0.4746   1.4956   2.2203   0.3532   \n",
       "\n",
       "       MB.5465  MB.5453  MB.5471  MB.5127  MB.4313  MB.4823  \n",
       "0      -1.7974   1.1339   0.0259  -0.3529  -1.2327   1.7217  \n",
       "1       3.5763   1.3429   0.5726   0.1731   0.5482   1.2239  \n",
       "2      -0.9275  -0.0587   0.5240  -0.0311   4.4925  -0.2173  \n",
       "3      -0.7141  -0.4324  -0.0336  -0.4003   2.4698  -0.7268  \n",
       "4      -1.0301   0.6082   0.5608   2.4222  -3.2853   0.4181  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "20382  -0.3989  -1.5529  -0.6349  -0.8160  -1.0902  -0.2811  \n",
       "20383   0.2231   0.0706   0.1188  -0.3231  -0.1251  -0.4265  \n",
       "20384  -0.2800   2.5337  -0.8272  -0.1200   4.2708  -1.0090  \n",
       "20385   0.3821   0.3254   0.8187  -0.5648   0.5931   0.9043  \n",
       "20386  -0.2418   0.5514  -0.9335   0.1794   0.0860   0.4096  \n",
       "\n",
       "[20387 rows x 1981 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "-10.23 34.7515\n",
      "(20387, 1980)\n",
      "AnnData object with n_obs × n_vars = 1980 × 20387\n",
      "    obs: 'Ground_Truth'          Ground_Truth\n",
      "MB.0362             1\n",
      "MB.0346             1\n",
      "MB.0386             1\n",
      "MB.0574             0\n",
      "MB.0185             0\n",
      "...               ...\n",
      "MB.5453             1\n",
      "MB.5471             0\n",
      "MB.5127             0\n",
      "MB.4313             0\n",
      "MB.4823             1\n",
      "\n",
      "[1980 rows x 1 columns] Empty DataFrame\n",
      "Columns: []\n",
      "Index: [RERE, RNF165, PHF7, CIDEA, TENT2, SLC17A3, SDS, ATP6V1C2, F3, FAM71C, LIN52, PCOTH, GRM1, FXN, SLC9A1, PML, CD164, MOB3A, HGC6.1.1, OR1J2, GNG5, TAF15, EXTL3, CNPY3, FAM174C, LOC154449, GATD3A, P2RX1, LRR1, ATP1B2, UBLCP1, LINC00937, IFNL3, DES, HERC2P9, PRR16, HIPK2, SHMT2, MRPS5, SNORD36C, SPN, CHRNA6, TBC1D22A, RPL35, SSTR4, ST6GALNAC4, TM2D1, RASD2, UBE2DNL, TFAP2D, ITGA10, ETFRF1, PLPPR1, MARS2, MAGEC1, PDIA6, FLJ41130, CYP2B6, SLC25A25, FGFBP2, LRRC23, PNCK, RPS24, NRDE2, GLT8D2, CASC2, CRACR2B, REEP3, ECI2, BTBD3, RBM17, LINC01140, TRNAU1AP, IL21R, RASSF4, PCDHA9, PLXNB2, OR8H2, ANTXR2, GALK2, FAM90A13, MIEN1, TMEM59, BCAN, TXNDC11, DOCK2, ARFIP1, LARGE1, PDXDC2P-NPIPB14P, RBMY1F, SRF, SLITRK3, ACMSD, KRT8, H2BC18, ATG10, ADAMTS6, CREB3L2, PANX3, STATH, ...]\n",
      "\n",
      "[20387 rows x 0 columns] [[21.15558619 21.71870658 22.00349032 ... 22.75780043 23.6437202\n",
      "  20.23543012]\n",
      " [25.46958194 23.53500884 20.38237942 ... 21.0708847  25.6256461\n",
      "  22.81404577]\n",
      " [22.73090048 21.2309505  23.31780843 ... 22.85806387 24.51274413\n",
      "  24.21173149]\n",
      " ...\n",
      " [21.95813835 23.12750798 22.67354357 ... 22.47590676 21.48705579\n",
      "  23.14151373]\n",
      " [20.00222314 23.96140636 32.73012238 ... 32.23725309 24.06122517\n",
      "  22.93387281]\n",
      " [26.57025666 25.46357947 22.25959561 ... 20.4995387  24.75306515\n",
      "  23.65327968]]\n"
     ]
    }
   ],
   "source": [
    "sample_id = df.iloc[:,0].values\n",
    "gene_id = df.columns[1:].values\n",
    "data_x = df.iloc[:,1:].values\n",
    "\n",
    "import numpy as np\n",
    "# confirm nan and inf in data_x\n",
    "print(np.isnan(data_x).any(), np.isinf(data_x).any())\n",
    "# set nan to 0\n",
    "data_x = np.nan_to_num(data_x)\n",
    "\n",
    "# normalize the data to 0-100\n",
    "# 找到数据的最小值和最大值\n",
    "min_val = np.min(data_x)\n",
    "max_val = np.max(data_x)\n",
    "print(min_val, max_val )\n",
    "# 将数据归一化到 0 到 100 的范围\n",
    "normalized_data_x = 100 * (data_x - min_val) / (max_val - min_val)\n",
    "print(normalized_data_x.shape)\n",
    "# create the adata matrix\n",
    "import anndata\n",
    "adata = anndata.AnnData(X = normalized_data_x.T, obs = pd.DataFrame(index = gene_id), var = pd.DataFrame(index = sample_id))\n",
    "adata.obs[\"Ground_Truth\"] = np.random.choice([0,1], adata.shape[0])\n",
    "print(adata, adata.obs, adata.var, adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.write(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1980 × 20387\n",
      "    obs: 'Ground_Truth'\n",
      "Index(['MB.0362', 'MB.0346', 'MB.0386', 'MB.0574', 'MB.0185', 'MB.0503',\n",
      "       'MB.0641', 'MB.0201', 'MB.0218', 'MB.0316',\n",
      "       ...\n",
      "       'MB.6192', 'MB.4820', 'MB.5527', 'MB.5167', 'MB.5465', 'MB.5453',\n",
      "       'MB.5471', 'MB.5127', 'MB.4313', 'MB.4823'],\n",
      "      dtype='object', length=1980)\n",
      "Index(['RERE', 'RNF165', 'PHF7', 'CIDEA', 'TENT2', 'SLC17A3', 'SDS',\n",
      "       'ATP6V1C2', 'F3', 'FAM71C',\n",
      "       ...\n",
      "       'SBF2-AS1', 'VN1R4', 'TRPV5', 'UGGT1', 'CR590356', 'VPS72', 'CSMD3',\n",
      "       'CC2D1A', 'IGSF9', 'FAM71A'],\n",
      "      dtype='object', length=20387)\n",
      " negative values: 0\n"
     ]
    }
   ],
   "source": [
    "# check the data\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "adata = sc.read(data_path)\n",
    "\n",
    "print(adata)\n",
    "print(adata.obs.index)\n",
    "print(adata.var.index)\n",
    "print(f\" negative values: {np.sum(adata.X<0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# adata.X 有多少nan\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# 假设 adata.X 是你的稀疏矩阵\n",
    "# 首先，检查它是否为稀疏矩阵\n",
    "if issparse(adata.X):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_para(var_idx=None, obs_idx='Ground_Truth', vocab_loc='/home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json', gene_vocab=None, use_key='X', filter_gene_by_counts=False, filter_cell_by_counts=200, normalize_total=10000.0, result_normed_key='X_normed', log1p=True, result_log1p_key='X_log1p', log1p_base=2, subset_hvg=False, hvg_use_key=None, hvg_flavor='seurat_v3', binning=None, result_binned_key='X_binned', tokenize_name='scBERT', return_pt=True, append_cls=True, include_zero_gene=False, cls_token='<cls>', max_len=16000, pad_token='<pad>', pad_value=-2, cls_appended=True, mask_ratio=0.15, mask_value=-1, preprocessed_loc=None, data_layer_name='X_log1p', label_key='Ground_Truth', batch_label_key=None, cls_nb=5, binarize=None, bins=None, bin_min=None, bin_max=None, save_in_obs=True, auto_map_str_labels=True, map_dict=None, n_splits=1, test_size=None, random_state=2023, shuffle=True, sort_seq_batch=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT\n",
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT \n",
    "dataset_para_cls = Dataset_para(\n",
    "                            var_idx=None,\n",
    "                            obs_idx=\"Ground_Truth\",\n",
    "                            vocab_loc=code_loc + \"/Experiment/support_data/vocab_16k.json\",\n",
    "                            filter_gene_by_counts=False,\n",
    "                            filter_cell_by_counts=200,\n",
    "                            log1p=True,\n",
    "                            log1p_base=2,\n",
    "\n",
    "                            #\n",
    "                            tokenize_name=\"scBERT\",\n",
    "                            cls_nb=5,\n",
    "                            data_layer_name=\"X_log1p\",\n",
    "                            label_key = target_label,#\"Ground_truth\",#\"Ground_truth\",\n",
    "\n",
    "                            test_size=None,#0.2, #use all data to inference\n",
    "                            binarize=None, # not binarize use original label\n",
    "\n",
    "                            )\n",
    "\n",
    "dataset_para_reg = Dataset_para(\n",
    "        vocab_loc=code_loc +\"/Experiment/support_data/vocab_16k.json\",\n",
    "        var_idx = None,#\"genes.gene_short_name\",\n",
    "        obs_idx=\"pseudotimes\",\n",
    "        filter_gene_by_counts=False,\n",
    "        filter_cell_by_counts=200,\n",
    "        log1p=True,\n",
    "        log1p_base=2,\n",
    "\n",
    "        tokenize_name=\"scBERT\",\n",
    "        cls_nb=1,\n",
    "        data_layer_name=\"X_log1p\",\n",
    "\n",
    "        auto_map_str_labels=False,\n",
    "        label_key = target_label,#\"pseudotimes\",\n",
    "\n",
    "        test_size=None,#0.2, #use all data to inference\n",
    "        binarize=None, # not binarize use original label for regression\n",
    "    )\n",
    "\n",
    "dataset_para = dataset_para_cls#dataset_para_cls\n",
    "print(dataset_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shi/anaconda3/envs/scLLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "scLLM - INFO - Initializing preprocessor ...\n",
      "scLLM - INFO - use default vocab from dataset_para\n",
      "scLLM - INFO - load vocab from /home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json\n",
      "scLLM - INFO - Load data from anndata object.\n",
      "scLLM - DEBUG - In original adata with gene 20387\n",
      "scLLM - DEBUG - In original adata with gene 20387\n",
      "scLLM - DEBUG - processing 0/16906\n",
      "scLLM - DEBUG - processing 2000/16906\n",
      "scLLM - DEBUG - processing 4000/16906\n",
      "scLLM - DEBUG - processing 6000/16906\n",
      "scLLM - DEBUG - processing 8000/16906\n",
      "scLLM - DEBUG - processing 10000/16906\n",
      "scLLM - DEBUG - processing 12000/16906\n",
      "scLLM - DEBUG - processing 14000/16906\n",
      "scLLM - DEBUG - processing 16000/16906\n",
      "scLLM - INFO - create anndata in scLLM format..\n",
      "scLLM - DEBUG - restore anndata in scLLM format..\n",
      "scLLM - INFO - Done.\n",
      "scLLM - INFO - Filtering cells by counts ...\n",
      "scLLM - INFO - Normalizing total counts ...\n",
      "scLLM - INFO - Log1p transforming ...\n",
      "scLLM - INFO - Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# if this is the first time to run, need this block to init translate=True\n",
    "# init preprocessor\n",
    "from scLLM.Dataset.Reader import scReader\n",
    "data_reader = scReader(dataset_para=dataset_para)\n",
    "# init vocab\n",
    "data_reader.init_vocab()\n",
    "\n",
    "# load data\n",
    "data_reader.load_adata(loc = data_path,translate=True)\n",
    "\n",
    "## preprocess\n",
    "data_reader.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择前的数据矩阵形状 (1980, 16906)\n",
      "选择后的数据矩阵形状 (1980, 16906)\n"
     ]
    }
   ],
   "source": [
    "target_stimulate = \"TGFb\"\n",
    "target_cellline = None #\"A549\" 'DU145', 'MCF7', 'OVCA420'\n",
    "map_stimulus = False\n",
    "map_cancer_type = False\n",
    "\n",
    "print(f\"选择前的数据矩阵形状 {data_reader.adata.shape}\")\n",
    "if map_stimulus:\n",
    "    stimilus_map = data_reader.adata.obs['stimulus']==target_stimulate\n",
    "    # filter out cells that are not stimulated by TGFb\n",
    "    new_adata = data_reader.adata[stimilus_map,:]\n",
    "    data_reader.adata = new_adata\n",
    "\n",
    "if map_cancer_type:\n",
    "    cancer_type_map = data_reader.adata.obs['CellLine']==target_cellline\n",
    "    # filter out cells that are not stimulated by TGFb\n",
    "    new_adata = data_reader.adata[cancer_type_map,:]\n",
    "    data_reader.adata = new_adata\n",
    "\n",
    "print(f\"选择后的数据矩阵形状 {data_reader.adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# get layer X_log1p\n",
    "data = data_reader.adata.layers[\"X_log1p\"] \n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "# set nan to 0\n",
    "if isinstance(data, csr_matrix):\n",
    "    # 使用 CSR 格式的稀疏矩阵可以直接通过 data.data 访问非零元素\n",
    "    data.data[np.isnan(data.data)] = 0\n",
    "    # 注意: 这里没有改变矩阵的稀疏结构，只是将非零元素中的 NaN 值替换为 0\n",
    "    data.data[np.isinf(data.data)] = data.data.max()\n",
    "else:\n",
    "    # 如果 data 不是稀疏矩阵，可以直接使用 numpy 的方法\n",
    "    data[np.isnan(data)] = 0\n",
    "    data[np.isinf(data)] = data.max()\n",
    "\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count}\")\n",
    "data_reader.adata.layers[\"X_log1p\"]  = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# data <0 的个数\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.sum(data.toarray()<0)\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.sum(data<0)\n",
    "\n",
    "print(f\"Negative values in adata.X: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "label_unique = data_reader.adata.obs[dataset_para.label_key].unique()\n",
    "print(label_unique)\n",
    "label_dict = {'fake_lable_0':0,'fake_lable_1':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fake label\n",
    "#data_reader.adata.obs[dataset_para.label_key]\n",
    "revert_dict = {v:k for k,v in label_dict.items()}\n",
    "# map to str label\n",
    "data_reader.adata.obs[dataset_para.label_key] = data_reader.adata.obs[dataset_para.label_key].map(revert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Map string labels to int automatically.\n",
      "scLLM - INFO - Mapping from {'fake_lable_1': 0, 'fake_lable_0': 1}\n",
      "scLLM - INFO - Discritize label Ground_Truth in obs_names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  1980\n",
      "no valset\n",
      "{'fake_lable_0': 0, 'fake_lable_1': 1}\n",
      "weights:  None\n"
     ]
    }
   ],
   "source": [
    "trainset,valset,weights = data_reader.postprocess()\n",
    "\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(trainset))\n",
    "print(\"valset size: \",len(valset)) if valset is not None else print(\"no valset\")\n",
    "print(label_dict)\n",
    "print(\"weights: \",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.sample_id = adata.obs.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# 为trainset 添加其他labels\n",
    "\n",
    "#target_task = f\"/TrVal_dataset_GT_{target_stimulate}_{target_cellline}.pkl\"\n",
    "target_task = f\"/TrVal_dataset_{target_label}.pkl\"\n",
    "loc = save_root + target_task\n",
    "# 保存 trainset 到文件，并关联相应labels\n",
    "with open(loc,\"wb\") as f:\n",
    "    dill.dump([trainset,valset,weights,label_dict],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB.0362    MB.0362\n",
      "MB.0346    MB.0346\n",
      "MB.0386    MB.0386\n",
      "MB.0574    MB.0574\n",
      "MB.0185    MB.0185\n",
      "            ...   \n",
      "MB.5453    MB.5453\n",
      "MB.5471    MB.5471\n",
      "MB.5127    MB.5127\n",
      "MB.4313    MB.4313\n",
      "MB.4823    MB.4823\n",
      "Length: 1980, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "# 假设adata和raw_adata是已经加载的Anndata对象\n",
    "\n",
    "# 定义一个函数来计算稀疏矩阵每行的哈希值\n",
    "def hash_sparse_row(row):\n",
    "    # 将稀疏矩阵行转换为密集格式然后计算哈希\n",
    "    return hash(tuple(row.toarray()[0]))\n",
    "\n",
    "data1 = trainset.data #adata.X\n",
    "data2 = data_reader.adata.layers[\"X_log1p\"] #raw_adata.X\n",
    "data2_source = data_reader.adata\n",
    "# 检查adata.X是否为稀疏矩阵，然后相应地计算哈希值\n",
    "if issparse(data1):\n",
    "    adata_hashes = [hash_sparse_row(data1[row,:]) for row in range(data1.shape[0])]\n",
    "else:\n",
    "    adata_hashes = [hash(tuple(row)) for row in adata.X.toarray()]\n",
    "\n",
    "# 同样的处理对raw_adata.X进行\n",
    "if issparse(data2):\n",
    "    raw_adata_hashes = [hash_sparse_row(data2[row,:]) for row in range(data2.shape[0])]\n",
    "else:\n",
    "    raw_adata_hashes = [hash(tuple(row)) for row in data2.toarray()]\n",
    "\n",
    "# 创建从raw_adata的行哈希值到其obs.index的映射\n",
    "hash_to_index_map = {hash_: index for hash_, index in zip(raw_adata_hashes, data2_source.obs.index)}\n",
    "\n",
    "\n",
    "# 创建一个列表来存储对应的raw_adata.obs.index\n",
    "mapped_indices = []\n",
    "\n",
    "# 对于adata中的每一行，找到对应的raw_adata.obs.index\n",
    "for i,hash_ in enumerate(adata_hashes):\n",
    "    mapped_index = hash_to_index_map.get(hash_, None)\n",
    "    if mapped_index is not None:\n",
    "        mapped_indices.append(mapped_index)\n",
    "    else:\n",
    "        # 如果找不到对应，可能需要处理这种情况\n",
    "        raise ValueError(f\"No matching index {i} found for hash: {str(hash_)}\" )\n",
    "\n",
    "# 将mapped_indices转换为Pandas Series对象，以便更方便地处理\n",
    "mapped_series = pd.Series(mapped_indices, index=adata.obs.index)\n",
    "\n",
    "# 打印或者返回映射结果\n",
    "print(mapped_series)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

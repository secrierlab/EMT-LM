{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "save_root = root + \"/Step_1_data/Dataset_cook_removed/\" #projects/scMultiNet_Data/Step_1_data/Dataset_cook_removed\n",
    "import sys\n",
    "sys.path.append(code_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a vocab list\n",
    "# this related with the gene2vec model\n",
    "#----> pre-trained part \n",
    "vocab_loc = code_loc +\"/support_data/vocab_gene2vec_16906.pkl\"\n",
    "target_label = 'Ground_truth' # the label to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = root+\"/Step_0_data/2024_05_19_Cook_emt_dataset_with_removal.h5ad\"  #/home/shi/WorkSpace/projects/scMultiNet_Data/Step_0_data/2024_05_19_Cook_emt_dataset_with_removal.h5ad\n",
    "data_path = root +  \"/Step_0_data/2024_05_20_Cook_emt_dataset_only_removal.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "adata = anndata.read_h5ad(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CellLine</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>pseudotimes</th>\n",
       "      <th>Ground_truth</th>\n",
       "      <th>Tissue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mix1_AAACCTGAGGATGGAA-0</th>\n",
       "      <td>A549</td>\n",
       "      <td>EGF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.48516449738804296</td>\n",
       "      <td>3d</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix1_AAACCTGTCTATCCTA-0</th>\n",
       "      <td>A549</td>\n",
       "      <td>EGF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.25346161999088135</td>\n",
       "      <td>8h_rm</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix1_AAACGGGGTTCGTGAT-0</th>\n",
       "      <td>A549</td>\n",
       "      <td>EGF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.6167297949786524</td>\n",
       "      <td>7d</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix1_AAAGCAAGTTGTGGCC-0</th>\n",
       "      <td>A549</td>\n",
       "      <td>EGF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.6523695007361208</td>\n",
       "      <td>8h_rm</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix1_AAAGTAGCACTGTTAG-0</th>\n",
       "      <td>A549</td>\n",
       "      <td>EGF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.34715971331363804</td>\n",
       "      <td>0d</td>\n",
       "      <td>Lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix4b_TCTATTGAGATGTAAC-11</th>\n",
       "      <td>OVCA420</td>\n",
       "      <td>TNF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.5429753869928555</td>\n",
       "      <td>3d_rm</td>\n",
       "      <td>Ovarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix4b_TCTTTCCCAGCGTTCG-11</th>\n",
       "      <td>OVCA420</td>\n",
       "      <td>TNF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.7734407184882754</td>\n",
       "      <td>3d</td>\n",
       "      <td>Ovarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix4b_TGGCCAGTCATCATTC-11</th>\n",
       "      <td>OVCA420</td>\n",
       "      <td>TNF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.7089686393043807</td>\n",
       "      <td>8h_rm</td>\n",
       "      <td>Ovarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix4b_TGTGGTAGTGTCTGAT-11</th>\n",
       "      <td>OVCA420</td>\n",
       "      <td>TNF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.6420790577610113</td>\n",
       "      <td>3d</td>\n",
       "      <td>Ovarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mix4b_TTCGAAGTCATGTGGT-11</th>\n",
       "      <td>OVCA420</td>\n",
       "      <td>TNF</td>\n",
       "      <td>Cook</td>\n",
       "      <td>0.6655429085624628</td>\n",
       "      <td>3d</td>\n",
       "      <td>Ovarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          CellLine stimulus Experiment          pseudotimes  \\\n",
       "Mix1_AAACCTGAGGATGGAA-0       A549      EGF       Cook  0.48516449738804296   \n",
       "Mix1_AAACCTGTCTATCCTA-0       A549      EGF       Cook  0.25346161999088135   \n",
       "Mix1_AAACGGGGTTCGTGAT-0       A549      EGF       Cook   0.6167297949786524   \n",
       "Mix1_AAAGCAAGTTGTGGCC-0       A549      EGF       Cook   0.6523695007361208   \n",
       "Mix1_AAAGTAGCACTGTTAG-0       A549      EGF       Cook  0.34715971331363804   \n",
       "...                            ...      ...        ...                  ...   \n",
       "Mix4b_TCTATTGAGATGTAAC-11  OVCA420      TNF       Cook   0.5429753869928555   \n",
       "Mix4b_TCTTTCCCAGCGTTCG-11  OVCA420      TNF       Cook   0.7734407184882754   \n",
       "Mix4b_TGGCCAGTCATCATTC-11  OVCA420      TNF       Cook   0.7089686393043807   \n",
       "Mix4b_TGTGGTAGTGTCTGAT-11  OVCA420      TNF       Cook   0.6420790577610113   \n",
       "Mix4b_TTCGAAGTCATGTGGT-11  OVCA420      TNF       Cook   0.6655429085624628   \n",
       "\n",
       "                          Ground_truth   Tissue  \n",
       "Mix1_AAACCTGAGGATGGAA-0             3d     Lung  \n",
       "Mix1_AAACCTGTCTATCCTA-0          8h_rm     Lung  \n",
       "Mix1_AAACGGGGTTCGTGAT-0             7d     Lung  \n",
       "Mix1_AAAGCAAGTTGTGGCC-0          8h_rm     Lung  \n",
       "Mix1_AAAGTAGCACTGTTAG-0             0d     Lung  \n",
       "...                                ...      ...  \n",
       "Mix4b_TCTATTGAGATGTAAC-11        3d_rm  Ovarian  \n",
       "Mix4b_TCTTTCCCAGCGTTCG-11           3d  Ovarian  \n",
       "Mix4b_TGGCCAGTCATCATTC-11        8h_rm  Ovarian  \n",
       "Mix4b_TGTGGTAGTGTCTGAT-11           3d  Ovarian  \n",
       "Mix4b_TTCGAAGTCATGTGGT-11           3d  Ovarian  \n",
       "\n",
       "[53290 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples in 0d,8h,1d,3d,7d only keep 7d+8h('8h_rm'), 7d+1d ('1d_rm'), 7d+3d ('3d_rm')\n",
    "adata = adata[~adata.obs[\"Ground_truth\"].isin([\"0d\",\"8h\",\"1d\",\"3d\",\"7d\"])]\n",
    "\n",
    "# remove samples not TGFb \n",
    "adata = adata[~adata.obs[\"stimulus\"].isin(['EGF', 'TNF'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732, 11058)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.write(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1732 × 11058\n",
      "    obs: 'CellLine', 'stimulus', 'Experiment', 'pseudotimes', 'Ground_truth', 'Tissue'\n",
      "    uns: 'source_paper'\n",
      "    obsm: 'X_pca', 'X_umap', 'X_umap_pseudo'\n",
      "Index(['Mix1_ACTTACTAGTGCGATG-1', 'Mix1_ATCATCTAGTAACCCT-1',\n",
      "       'Mix1_CACAAACCACGGACAA-1', 'Mix1_CCAGCGACACCAGTTA-1',\n",
      "       'Mix1_GCGCAACGTCGGATCC-1', 'Mix1_GGAAAGCCAACTTGAC-1',\n",
      "       'Mix1_GGGAGATTCGCATGAT-1', 'Mix1_GTGTTAGAGTGCGATG-1',\n",
      "       'Mix1_TCAGCTCAGTACGTAA-1', 'Mix1_TCGTACCAGTCCTCCT-1',\n",
      "       ...\n",
      "       'Mix4b_GCTTGAAAGGGTCGAT-10', 'Mix4b_GGGAGATAGTGGCACA-10',\n",
      "       'Mix4b_GGGCATCTCCGTACAA-10', 'Mix4b_GGTGCGTTCATCACCC-10',\n",
      "       'Mix4b_GTCCTCAAGGCCCTTG-10', 'Mix4b_GTGAAGGTCGAACGGA-10',\n",
      "       'Mix4b_GTTACAGTCCTGCCAT-10', 'Mix4b_TAGGCATCAGGATTGG-10',\n",
      "       'Mix4b_TCGAGGCAGTCCGTAT-10', 'Mix4b_TGGCCAGAGCGACGTA-10'],\n",
      "      dtype='object', length=1732)\n",
      "Index(['FO538757.2', 'AP006222.2', 'RP11-206L10.9', 'FAM41C', 'SAMD11',\n",
      "       'NOC2L', 'KLHL17', 'PLEKHN1', 'HES4', 'ISG15',\n",
      "       ...\n",
      "       'MT-ATP6', 'MT-CO3', 'MT-ND3', 'MT-ND4L', 'MT-ND4', 'MT-ND5', 'MT-ND6',\n",
      "       'MT-CYB', 'AC007325.4', 'AC240274.1'],\n",
      "      dtype='object', length=11058)\n",
      " negative values: 0\n"
     ]
    }
   ],
   "source": [
    "# check the data\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "adata = sc.read(data_path)\n",
    "\n",
    "print(adata)\n",
    "print(adata.obs.index)\n",
    "print(adata.var.index)\n",
    "print(f\" negative values: {np.sum(adata.X<0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0 with shape (1732, 11058)\n"
     ]
    }
   ],
   "source": [
    "# adata.X 有多少nan\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# 假设 adata.X 是你的稀疏矩阵\n",
    "# 首先，检查它是否为稀疏矩阵\n",
    "if issparse(adata.X):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(adata.X).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count} with shape {adata.X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_para(var_idx=None, obs_idx='Ground_truth', vocab_loc='/home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json', gene_vocab=None, use_key='X', filter_gene_by_counts=False, filter_cell_by_counts=0, normalize_total=10000.0, result_normed_key='X_normed', log1p=True, result_log1p_key='X_log1p', log1p_base=2, subset_hvg=False, hvg_use_key=None, hvg_flavor='seurat_v3', binning=None, result_binned_key='X_binned', tokenize_name='scBERT', return_pt=True, append_cls=True, include_zero_gene=False, cls_token='<cls>', max_len=16000, pad_token='<pad>', pad_value=-2, cls_appended=True, mask_ratio=0.15, mask_value=-1, preprocessed_loc=None, data_layer_name='X_log1p', label_key='Ground_truth', batch_label_key=None, cls_nb=5, binarize=None, bins=None, bin_min=None, bin_max=None, save_in_obs=True, auto_map_str_labels=True, map_dict=None, n_splits=1, test_size=None, random_state=2023, shuffle=True, sort_seq_batch=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT\n",
    "\n",
    "from scLLM.Dataset.paras import Dataset_para\n",
    "# define pre-processing by follow original implementation of scBERT \n",
    "dataset_para_cls = Dataset_para(\n",
    "                            var_idx=None,\n",
    "                            obs_idx=\"Ground_truth\",\n",
    "                            vocab_loc=code_loc + \"/Experiment/support_data/vocab_16k.json\",\n",
    "                            filter_gene_by_counts=False,\n",
    "                            filter_cell_by_counts=0,\n",
    "                            log1p=True,\n",
    "                            log1p_base=2,\n",
    "\n",
    "                            #\n",
    "                            tokenize_name=\"scBERT\",\n",
    "                            cls_nb=5,\n",
    "                            data_layer_name=\"X_log1p\",\n",
    "                            label_key = target_label,#\"Ground_truth\",#\"Ground_truth\",\n",
    "\n",
    "                            test_size=None,#0.2, #use all data to inference\n",
    "                            binarize=None, # not binarize use original label\n",
    "\n",
    "                            )\n",
    "\n",
    "dataset_para_reg = Dataset_para(\n",
    "        vocab_loc=code_loc +\"/Experiment/support_data/vocab_16k.json\",\n",
    "        var_idx = None,#\"genes.gene_short_name\",\n",
    "        obs_idx=\"pseudotimes\",\n",
    "        filter_gene_by_counts=False,\n",
    "        filter_cell_by_counts=200,\n",
    "        log1p=True,\n",
    "        log1p_base=2,\n",
    "\n",
    "        tokenize_name=\"scBERT\",\n",
    "        cls_nb=1,\n",
    "        data_layer_name=\"X_log1p\",\n",
    "\n",
    "        auto_map_str_labels=False,\n",
    "        label_key = target_label,#\"pseudotimes\",\n",
    "\n",
    "        test_size=None,#0.2, #use all data to inference\n",
    "        binarize=None, # not binarize use original label for regression\n",
    "    )\n",
    "\n",
    "dataset_para = dataset_para_cls#dataset_para_cls\n",
    "print(dataset_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shi/anaconda3/envs/scLLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "scLLM - INFO - Initializing preprocessor ...\n",
      "scLLM - INFO - use default vocab from dataset_para\n",
      "scLLM - INFO - load vocab from /home/shi/WorkSpace/projects/scMultiNet_workspace//Experiment/support_data/vocab_16k.json\n",
      "scLLM - INFO - Load data from anndata object.\n",
      "scLLM - DEBUG - In original adata with gene 11058\n",
      "scLLM - DEBUG - In original adata with gene 11058\n",
      "scLLM - DEBUG - processing 0/16906\n",
      "scLLM - DEBUG - processing 2000/16906\n",
      "scLLM - DEBUG - processing 4000/16906\n",
      "scLLM - DEBUG - processing 6000/16906\n",
      "scLLM - DEBUG - processing 8000/16906\n",
      "scLLM - DEBUG - processing 10000/16906\n",
      "scLLM - DEBUG - processing 12000/16906\n",
      "scLLM - DEBUG - processing 14000/16906\n",
      "scLLM - DEBUG - processing 16000/16906\n",
      "scLLM - INFO - create anndata in scLLM format..\n",
      "scLLM - DEBUG - restore anndata in scLLM format..\n",
      "scLLM - INFO - Done.\n"
     ]
    }
   ],
   "source": [
    "# if this is the first time to run, need this block to init translate=True\n",
    "# init preprocessor\n",
    "from scLLM.Dataset.Reader import scReader\n",
    "data_reader = scReader(dataset_para=dataset_para)\n",
    "# init vocab\n",
    "data_reader.init_vocab()\n",
    "\n",
    "# load data\n",
    "data_reader.load_adata(loc = data_path,translate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1732x16906 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 5809163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reader.adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Preprocessing data with shape: (1732, 16906) ...\n",
      "scLLM - INFO - Filtering cells by counts ...\n",
      "scLLM - INFO - Filtered cells: 1732\n",
      "scLLM - INFO - Normalizing total counts ...\n",
      "scLLM - INFO - Log1p transforming ...\n",
      "scLLM - INFO - Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "## preprocess\n",
    "data_reader.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 1732 × 16906\n",
      "    obs: 'Ground_truth', 'n_counts'\n",
      "    uns: 'log1p'\n",
      "    layers: 'X_normed', 'X_log1p' (1732, 16906)\n"
     ]
    }
   ],
   "source": [
    "print(data_reader.adata, data_reader.adata.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# get layer X_log1p\n",
    "data = data_reader.adata.layers[\"X_log1p\"] \n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "# set nan to 0\n",
    "if isinstance(data, csr_matrix):\n",
    "    # 使用 CSR 格式的稀疏矩阵可以直接通过 data.data 访问非零元素\n",
    "    data.data[np.isnan(data.data)] = 0\n",
    "    # 注意: 这里没有改变矩阵的稀疏结构，只是将非零元素中的 NaN 值替换为 0\n",
    "    data.data[np.isinf(data.data)] = data.data.max()\n",
    "else:\n",
    "    # 如果 data 不是稀疏矩阵，可以直接使用 numpy 的方法\n",
    "    data[np.isnan(data)] = 0\n",
    "    data[np.isinf(data)] = data.max()\n",
    "\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data.toarray()).sum()\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.isnan(data).sum()\n",
    "\n",
    "print(f\"NaN values in adata.X: {nan_count}\")\n",
    "data_reader.adata.layers[\"X_log1p\"]  = data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in adata.X: 0\n"
     ]
    }
   ],
   "source": [
    "# data <0 的个数\n",
    "if issparse(data):\n",
    "    # 将稀疏矩阵转换为密集格式，然后计算 NaN 值的数量\n",
    "    nan_count = np.sum(data.toarray()<0)\n",
    "else:\n",
    "    # 如果 adata.X 不是稀疏矩阵，直接计算 NaN 值的数量\n",
    "    nan_count = np.sum(data<0)\n",
    "\n",
    "print(f\"Negative values in adata.X: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1732, 16906)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1d_rm', '8h_rm', '3d_rm']\n",
      "Categories (3, object): ['1d_rm', '3d_rm', '8h_rm']\n"
     ]
    }
   ],
   "source": [
    "label_unique = data_reader.adata.obs[dataset_para.label_key].unique()\n",
    "print(label_unique)\n",
    "data_reader.adata.obs[\"str_\"+dataset_para.label_key] = data_reader.adata.obs[dataset_para.label_key]\n",
    "\n",
    "#\n",
    "if data_reader.para.auto_map_str_labels:\n",
    "    if data_reader.para.map_dict:\n",
    "        print(data_reader.para.map_dict)\n",
    "    else:\n",
    "        data_reader.para.map_dict = {'8h_rm': 0,'1d_rm': 1,  '3d_rm': 2}\n",
    "else:\n",
    "\n",
    "    label_dict = {'8h_rm':0,'1d_rm':1,'3d_rm':2}\n",
    "    # map obs label to int\n",
    "    data_reader.adata.obs[dataset_para.label_key] = data_reader.adata.obs[dataset_para.label_key].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Map string labels to int automatically.\n",
      "scLLM - INFO - Mapping from {'8h_rm': 0, '1d_rm': 1, '3d_rm': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_dict: {'8h_rm': 0, '1d_rm': 1, '3d_rm': 2}, name_list: ['1d_rm', '8h_rm', '3d_rm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scLLM - INFO - Discritize label Ground_truth in obs_names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  1732\n",
      "no valset\n",
      "{'8h_rm': 0, '1d_rm': 1, '3d_rm': 2}\n",
      "weights:  None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset,valset,weights = data_reader.postprocess()\n",
    "\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(trainset))\n",
    "print(\"valset size: \",len(valset)) if valset is not None else print(\"no valset\")\n",
    "#label_dict = {'1d_rm': 0, '8h_rm': 1, '3d_rm': 2}\n",
    "print(data_reader.para.map_dict)\n",
    "print(\"weights: \",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.sample_id = data_reader.adata.obs.index.to_list()\n",
    "trainset.tissue_type = adata.obs[\"Tissue\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732 1732 (1732, 16906) ['Mix1_ACTTACTAGTGCGATG-1', 'Mix1_ATCATCTAGTAACCCT-1', 'Mix1_CACAAACCACGGACAA-1', 'Mix1_CCAGCGACACCAGTTA-1', 'Mix1_GCGCAACGTCGGATCC-1']\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset.sample_id), len(trainset.label), trainset.data.shape,trainset.sample_id[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# 为trainset 添加其他labels\n",
    "\n",
    "#target_task = f\"/TrVal_dataset_GT_{target_stimulate}_{target_cellline}.pkl\"\n",
    "target_task = f\"/TrVal_dataset_{target_label}.pkl\"\n",
    "loc = save_root + target_task\n",
    "# 保存 trainset 到文件，并关联相应labels\n",
    "with open(loc,\"wb\") as f:\n",
    "    dill.dump([trainset,valset,weights,data_reader.para.map_dict],f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

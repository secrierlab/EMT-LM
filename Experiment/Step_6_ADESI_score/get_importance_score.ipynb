{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  5881\n",
      "valset size:  1471\n",
      "{'3d': 0, '7d': 1, '1d': 2, '8h': 3, '0d': 4}\n"
     ]
    }
   ],
   "source": [
    "# 把scLLM的位置添加进system path保证可以import scLLM\n",
    "import sys\n",
    "root = \"/home/shi/WorkSpace/projects/scMultiNet_Data/\"\n",
    "code_loc = \"/home/shi/WorkSpace/projects/scMultiNet_workspace/\"\n",
    "sys.path.append(code_loc)\n",
    "# 数据集读取\n",
    "import dill\n",
    "raw_data_loc = root + \"/Step_1_data/Dataset_cook/TrVal_dataset_PC_TGFb_GTlabel5.pkl\"\n",
    "# 用dill打开loc0的pkl 文件读取dataset\n",
    "with open(raw_data_loc,\"rb\") as f:\n",
    "    [trainset,valset,_,label_dict] = dill.load(f)\n",
    "# 输出数据集信息\n",
    "print(\"trainset size: \",len(trainset))\n",
    "print(\"valset size: \",len(valset)) if valset is not None else print(\"no valset\")\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1BG', 'A1CF', 'A2M', 'A2ML1', 'A4GALT', 'A4GNT', 'AAAS', 'AACS', 'AADAC', 'AADACL2', 'AADAT', 'AAGAB', 'AAK1', 'AAMDC', 'AAMP', 'AANAT', 'AAR2', 'AARS2', 'AARSD1', 'AASDH']\n",
      "16907\n"
     ]
    }
   ],
   "source": [
    "# vocab 读取 \n",
    "vocab_loc = code_loc + \"/Experiment/support_data/vocab_16k.json\"\n",
    "import json\n",
    "with open(vocab_loc,\"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "\n",
    "# 根据字典的值进行排序，并获取排序后的键\n",
    "sorted_genes = sorted(vocab, key=vocab.get)\n",
    "\n",
    "# 现在 sorted_genes 是一个按值排序的基因名称列表\n",
    "sorted_genes.append(\"CLS\")\n",
    "print(sorted_genes[:20])\n",
    "print(len(sorted_genes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 步骤 0: 数据位置\n",
    "data_locs = [\n",
    "    root+\"/Step_6_data/data/multi_cls0.pkl\",\n",
    "    root+\"/Step_6_data/data/multi_cls1.pkl\",\n",
    "    root+\"/Step_6_data/data/multi_cls2.pkl\",\n",
    "    root+\"/Step_6_data/data/multi_cls3.pkl\",\n",
    "    root+\"/Step_6_data/data/multi_cls4.pkl\",\n",
    "]\n",
    "# 步骤 1: 加载数据\n",
    "# 文件保存在pkl\n",
    "import pickle\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        [pred_list,label_list,weights_list,weighted_feature_list] = pickle.load(f)\n",
    "    print(pred_list.shape)\n",
    "    print(label_list.shape)\n",
    "    print(weights_list.shape)\n",
    "    print(weighted_feature_list.shape)\n",
    "    return pred_list,label_list,weights_list,weighted_feature_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1471, 2)\n",
      "(1471, 1)\n",
      "(1471, 16907)\n",
      "(1471, 16907)\n",
      "(1471, 2)\n",
      "(1471, 1)\n",
      "(1471, 16907)\n",
      "(1471, 16907)\n",
      "(1471, 2)\n",
      "(1471, 1)\n",
      "(1471, 16907)\n",
      "(1471, 16907)\n",
      "(1471, 2)\n",
      "(1471, 1)\n",
      "(1471, 16907)\n",
      "(1471, 16907)\n",
      "(1471, 2)\n",
      "(1471, 1)\n",
      "(1471, 16907)\n",
      "(1471, 16907)\n"
     ]
    }
   ],
   "source": [
    "pred_lists = []\n",
    "weights_lists = []\n",
    "weighted_feature_lists = []\n",
    "for l in data_locs:\n",
    "    pred_list,label_list,weights_list,weighted_feature_list = load_data(l)\n",
    "    pred_lists.append(pred_list)\n",
    "    weights_lists.append(weights_list)\n",
    "    weighted_feature_lists.append(weighted_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_lists 是一个包含5个模型 weights_list 的列表\n",
    "# 初始化 model_weights\n",
    "model_weights = np.zeros([weights_lists[0].shape[0] , weights_lists[0].shape[1]])\n",
    "# 初始化 avg_weights\n",
    "avg_0 = [np.zeros([weights_lists[0].shape[1],1]),0]\n",
    "avg_1 = [np.zeros([weights_lists[0].shape[1],1]),0]\n",
    "avg_2 = [np.zeros([weights_lists[0].shape[1],1]),0]\n",
    "avg_3 = [np.zeros([weights_lists[0].shape[1],1]),0]\n",
    "avg_4 = [np.zeros([weights_lists[0].shape[1],1]),0]\n",
    "# 遍历每个样本\n",
    "for i in range(weights_lists[0].shape[0]):\n",
    "    # 获取当前样本的真实类别\n",
    "    label = int(label_list[i])\n",
    "\n",
    "    # 选择并复制对应类别的 weights_list\n",
    "    model_weights[i, :] = weights_lists[label][i, :]\n",
    "    # 更新 avg_weights\n",
    "    if label == 0:\n",
    "        avg_0[0] += weights_lists[label][i, :].reshape(-1,1)\n",
    "        avg_0[1] += 1\n",
    "    elif label == 1:\n",
    "        avg_1[0] += weights_lists[label][i, :].reshape(-1,1)\n",
    "        avg_1[1] += 1\n",
    "    elif label == 2:\n",
    "        avg_2[0] += weights_lists[label][i, :].reshape(-1,1)\n",
    "        avg_2[1] += 1\n",
    "    elif label == 3:\n",
    "        avg_3[0] += weights_lists[label][i, :].reshape(-1,1)\n",
    "        avg_3[1] += 1\n",
    "    elif label == 4:\n",
    "        avg_4[0] += weights_lists[label][i, :].reshape(-1,1)\n",
    "        avg_4[1] += 1\n",
    "\n",
    "# 计算平均权重\n",
    "avg_0 = avg_0[0] / avg_0[1]\n",
    "avg_1 = avg_1[0] / avg_1[1]\n",
    "avg_2 = avg_2[0] / avg_2[1]\n",
    "avg_3 = avg_3[0] / avg_3[1]\n",
    "avg_4 = avg_4[0] / avg_4[1]\n",
    "\n",
    "rev_label_dict = {v:k for k,v in label_dict.items()}\n",
    "dict_score = {\n",
    "    rev_label_dict[0]:avg_0.flatten(),\n",
    "    rev_label_dict[1]:avg_1.flatten(),\n",
    "    rev_label_dict[2]:avg_2.flatten(),\n",
    "    rev_label_dict[3]:avg_3.flatten(),\n",
    "    rev_label_dict[4]:avg_4.flatten(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 从dict_score生成pandas dataframe，每行的index是基因名称sorted_genes\n",
    "df = pd.DataFrame.from_dict(dict_score, orient='index', columns=sorted_genes)\n",
    "df = df.T\n",
    "df.to_csv(root+\"/Step_6_data/avg_attention_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_lists 是一个包含5个模型 weights_list 的列表\n",
    "# 初始化 model_weights\n",
    "model_weight_features = np.zeros([weighted_feature_lists[0].shape[0] , weighted_feature_lists[0].shape[1]])\n",
    "# 初始化 avg_weights\n",
    "avg_0 = [np.zeros([weighted_feature_lists[0].shape[1],1]),0]\n",
    "avg_1 = [np.zeros([weighted_feature_lists[0].shape[1],1]),0]\n",
    "avg_2 = [np.zeros([weighted_feature_lists[0].shape[1],1]),0]\n",
    "avg_3 = [np.zeros([weighted_feature_lists[0].shape[1],1]),0]\n",
    "avg_4 = [np.zeros([weighted_feature_lists[0].shape[1],1]),0]\n",
    "# 遍历每个样本\n",
    "for i in range(weighted_feature_lists[0].shape[0]):\n",
    "    # 获取当前样本的真实类别\n",
    "    label = int(label_list[i])\n",
    "\n",
    "    # 选择并复制对应类别的 weights_list\n",
    "    model_weight_features[i, :] = weighted_feature_lists[label][i, :]\n",
    "    # 更新 avg_weights\n",
    "    if label == 0:\n",
    "        avg_0[0] += weighted_feature_lists[label][i, :].reshape(-1,1)\n",
    "        avg_0[1] += 1\n",
    "    elif label == 1:\n",
    "        avg_1[0] += weighted_feature_lists[label][i, :].reshape(-1,1)\n",
    "        avg_1[1] += 1\n",
    "    elif label == 2:\n",
    "        avg_2[0] += weighted_feature_lists[label][i, :].reshape(-1,1)\n",
    "        avg_2[1] += 1\n",
    "    elif label == 3:\n",
    "        avg_3[0] += weighted_feature_lists[label][i, :].reshape(-1,1)\n",
    "        avg_3[1] += 1\n",
    "    elif label == 4:\n",
    "        avg_4[0] += weighted_feature_lists[label][i, :].reshape(-1,1)\n",
    "        avg_4[1] += 1\n",
    "\n",
    "# 计算平均权重\n",
    "avg_0 = avg_0[0] / avg_0[1]\n",
    "avg_1 = avg_1[0] / avg_1[1]\n",
    "avg_2 = avg_2[0] / avg_2[1]\n",
    "avg_3 = avg_3[0] / avg_3[1]\n",
    "avg_4 = avg_4[0] / avg_4[1]\n",
    "\n",
    "rev_label_dict = {v:k for k,v in label_dict.items()}\n",
    "dict_score = {\n",
    "    rev_label_dict[0]:avg_0.flatten(),\n",
    "    rev_label_dict[1]:avg_1.flatten(),\n",
    "    rev_label_dict[2]:avg_2.flatten(),\n",
    "    rev_label_dict[3]:avg_3.flatten(),\n",
    "    rev_label_dict[4]:avg_4.flatten(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从dict_score生成pandas dataframe，每行的index是基因名称sorted_genes\n",
    "df = pd.DataFrame.from_dict(dict_score, orient='index', columns=sorted_genes)\n",
    "df = df.T\n",
    "df.to_csv(root+\"/Step_6_data/avg_attention_x_gene_expression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(root+\"/Step_6_data/avg_weight_features.csv\")\n",
    "# 重命名第一列\n",
    "df = df.rename(columns={\"Unnamed: 0\":\"gene\"})\n",
    "df = df.set_index(\"gene\")\n",
    "\n",
    "# 获取每个类别排名前10的基因\n",
    "top_10_genes = {}\n",
    "for label in [\"0d\",\"8h\",\"1d\",\"3d\",\"7d\"]:\n",
    "    top_10_genes[label] = df[label].sort_values(ascending=False).index[:50].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top_10_genes).to_csv(root+\"/Step_6_data/top_50_genes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
